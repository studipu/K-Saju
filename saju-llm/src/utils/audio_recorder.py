"""
ìŒì„± ë…¹ìŒ ë° STT ì²˜ë¦¬ ëª¨ë“ˆ
OpenAI Whisper APIë¥¼ í™œìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
"""
import os
import time
import wave
import tempfile
from typing import Optional, Dict, Any

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    pyaudio = None
    PYAUDIO_AVAILABLE = False

from openai import OpenAI

class AudioRecorder:
    """ìŒì„± ë…¹ìŒ ë° STT ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, api_key: str = None):
        """
        AudioRecorder ì´ˆê¸°í™”

        Args:
            api_key: OpenAI API í‚¤
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key or self.api_key == "your_openai_api_key_here":
            raise ValueError("OpenAI API key is required for STT functionality")

        self.client = OpenAI(api_key=self.api_key)

        # ì˜¤ë””ì˜¤ ì„¤ì •
        self.sample_rate = 16000
        self.chunk_size = 1024
        self.channels = 1

        # PyAudio ì´ˆê¸°í™”
        if PYAUDIO_AVAILABLE:
            self.audio_format = pyaudio.paInt16
            self.audio = pyaudio.PyAudio()
        else:
            raise ImportError("pyaudio is required for audio recording. Please install: pip install pyaudio")

    def record_audio(self, duration: int = 10) -> str:
        """
        ìŒì„± ë…¹ìŒ

        Args:
            duration: ë…¹ìŒ ì‹œê°„ (ì´ˆ)

        Returns:
            ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        print("ğŸ¤ ìŒì„± ì…ë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print(f"   {duration}ì´ˆê°„ ë…¹ìŒë©ë‹ˆë‹¤.")

        # ì„ì‹œ íŒŒì¼ ìƒì„±
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        temp_filename = temp_file.name
        temp_file.close()

        # ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
        stream = self.audio.open(
            format=self.audio_format,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )

        print("ğŸ”´ ë…¹ìŒ ì‹œì‘!")

        frames = []
        start_time = time.time()

        try:
            while True:
                data = stream.read(self.chunk_size)
                frames.append(data)

                elapsed_time = time.time() - start_time

                # ì‹œê°„ ì²´í¬
                if elapsed_time >= duration:
                    print(f"â° {duration}ì´ˆê°€ ê²½ê³¼í•˜ì—¬ ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

        except KeyboardInterrupt:
            print("\nâ¹ï¸  ì‚¬ìš©ìê°€ ë…¹ìŒì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")

        finally:
            stream.stop_stream()
            stream.close()

        # WAV íŒŒì¼ë¡œ ì €ì¥
        with wave.open(temp_filename, 'wb') as wav_file:
            wav_file.setnchannels(self.channels)
            wav_file.setsampwidth(self.audio.get_sample_size(self.audio_format))
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes(b''.join(frames))

        print(f"ğŸ’¾ ë…¹ìŒ ì™„ë£Œ: {len(frames) * self.chunk_size / self.sample_rate:.1f}ì´ˆ")
        return temp_filename

    def transcribe_audio(self, audio_file_path: str, language: str = "ko") -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ìŒì„± ì–¸ì–´ ì½”ë“œ (ko, en ë“±)

        Returns:
            STT ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            print("ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")

            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=language,
                    response_format="verbose_json"
                )

            result = {
                "success": True,
                "text": transcript.text,
                "language": transcript.language,
                "duration": transcript.duration,
                "confidence": getattr(transcript, 'confidence', None)
            }

            print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: '{transcript.text}'")
            return result

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "text": ""
            }
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.unlink(audio_file_path)
            except:
                pass

    def record_and_transcribe(self, duration: int = 10, language: str = "ko") -> Dict[str, Any]:
        """
        ë…¹ìŒê³¼ STTë¥¼ í•œ ë²ˆì— ì²˜ë¦¬

        Args:
            duration: ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
            language: ìŒì„± ì–¸ì–´ ì½”ë“œ

        Returns:
            STT ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë…¹ìŒ
            audio_file = self.record_audio(duration=duration)

            # STT ì²˜ë¦¬
            result = self.transcribe_audio(audio_file, language=language)

            return result

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "text": ""
            }

    def __del__(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self, 'audio') and self.audio:
            self.audio.terminate()